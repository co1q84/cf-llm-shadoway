// æµ‹è¯•ç”¨ä¾‹ - éªŒè¯åŒæ¨¡å¼APIä»£ç†åŠŸèƒ½
const API_BASE = 'https://your-worker.workers.dev'; // æ›¿æ¢ä¸ºä½ çš„WorkeråŸŸå
const AUTH_TOKEN = 'your-secure-token';             // æ›¿æ¢ä¸ºä½ çš„è®¤è¯ä»¤ç‰Œ

// æµ‹è¯•é…ç½®
const TESTS = {
  claude: {
    gemini: {
      url: `${API_BASE}/${AUTH_TOKEN}/claude/gemini/v1/messages`,
      headers: {
        'x-api-key': 'YOUR_GEMINI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gemini-2.5-flash',
        max_tokens: 100,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    },
    gemini_stream: {
      url: `${API_BASE}/${AUTH_TOKEN}/claude/gemini/v1/messages`,
      headers: {
        'x-api-key': 'YOUR_GEMINI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gemini-2.5-flash',
        max_tokens: 100,
        stream: true,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    },
    openai: {
      url: `${API_BASE}/${AUTH_TOKEN}/claude/openai/v1/messages`,
      headers: {
        'x-api-key': 'YOUR_OPENAI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gpt-4o-mini',
        max_tokens: 100,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    }
  },
  openai: {
    gemini: {
      url: `${API_BASE}/${AUTH_TOKEN}/openai/gemini/v1/chat/completions`,
      headers: {
        'authorization': 'Bearer YOUR_GEMINI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gemini-2.5-flash',
        max_tokens: 100,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    },
    gemini_stream: {
      url: `${API_BASE}/${AUTH_TOKEN}/openai/gemini/v1/chat/completions`,
      headers: {
        'authorization': 'Bearer YOUR_GEMINI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gemini-2.5-flash',
        max_tokens: 100,
        stream: true,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    },
    openai: {
      url: `${API_BASE}/${AUTH_TOKEN}/openai/openai/v1/chat/completions`,
      headers: {
        'authorization': 'Bearer YOUR_OPENAI_API_KEY',
        'Content-Type': 'application/json'
      },
      body: {
        model: 'gpt-4o-mini',
        max_tokens: 100,
        messages: [
          { role: 'user', content: 'Say hello in Chinese' }
        ]
      }
    }
  }
};

async function runTest(name, config) {
  console.log(`\nğŸ§ª Testing ${name}...`);
  console.log(`URL: ${config.url}`);
  console.log(`Stream: ${config.body.stream || false}`);
  
  try {
    const response = await fetch(config.url, {
      method: 'POST',
      headers: config.headers,
      body: JSON.stringify(config.body)
    });
    
    console.log(`Status: ${response.status}`);
    console.log(`Content-Type: ${response.headers.get('content-type')}`);
    
    if (response.ok) {
      // æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼å“åº”
      if (response.headers.get('content-type')?.includes('text/event-stream')) {
        console.log('âœ… Stream Success!');
        console.log('Stream response detected, reading first few chunks...');
        
        const reader = response.body.getReader();
        let chunks = 0;
        try {
          while (chunks < 3) {
            const { done, value } = await reader.read();
            if (done) break;
            
            const chunk = new TextDecoder().decode(value);
            console.log(`Chunk ${chunks + 1}:`, chunk.slice(0, 100) + '...');
            chunks++;
          }
        } finally {
          reader.releaseLock();
        }
      } else {
        const data = await response.json();
        console.log('âœ… Non-stream Success!');
        console.log('Response preview:', JSON.stringify(data, null, 2).slice(0, 200) + '...');
      }
    } else {
      const error = await response.text();
      console.log('âŒ Failed!');
      console.log('Error:', error);
    }
  } catch (error) {
    console.log('âŒ Network Error!');
    console.log('Error:', error.message);
  }
}

async function runAllTests() {
  console.log('ğŸš€ CF LLM Shadoway Test Suite');
  console.log('='.repeat(50));
  
  console.log('\nğŸ“‹ Test Configuration:');
  console.log(`Base URL: ${API_BASE}`);
  console.log(`Auth Token: ${AUTH_TOKEN.slice(0, 8)}...`);
  
  console.log('\nâš ï¸  Please update API keys in the test configuration before running!');
  
  // Claudeæ ¼å¼æµ‹è¯•
  console.log('\nğŸ”µ Testing Claude Format API...');
  await runTest('Claude â†’ Gemini', TESTS.claude.gemini);
  await runTest('Claude â†’ Gemini (Stream)', TESTS.claude.gemini_stream);
  await runTest('Claude â†’ OpenAI', TESTS.claude.openai);
  
  // OpenAIæ ¼å¼æµ‹è¯•
  console.log('\nğŸŸ¢ Testing OpenAI Format API...');
  await runTest('OpenAI â†’ Gemini', TESTS.openai.gemini);
  await runTest('OpenAI â†’ Gemini (Stream)', TESTS.openai.gemini_stream);
  await runTest('OpenAI â†’ OpenAI', TESTS.openai.openai);
  
  console.log('\nâœ¨ Test suite completed!');
  console.log('\nğŸ“– Manual Testing Commands:');
  console.log('Copy and paste these curl commands to test manually:\n');
  
  // ç”Ÿæˆcurlå‘½ä»¤
  Object.entries(TESTS).forEach(([format, providers]) => {
    Object.entries(providers).forEach(([provider, config]) => {
      const authHeader = config.headers['x-api-key'] 
        ? `-H "x-api-key: ${config.headers['x-api-key']}"` 
        : `-H "authorization: ${config.headers.authorization}"`;
      
      console.log(`# ${format.toUpperCase()} â†’ ${provider.toUpperCase()}`);
      console.log(`curl -X POST "${config.url}" \\`);
      console.log(`  ${authHeader} \\`);
      console.log(`  -H "Content-Type: application/json" \\`);
      console.log(`  -d '${JSON.stringify(config.body, null, 2)}'`);
      console.log('');
    });
  });
}

// Claude Codeé›†æˆæµ‹è¯•
function generateClaudeCodeConfig() {
  console.log('\nğŸ¯ Claude Code Integration Examples:');
  console.log('='.repeat(50));
  
  const configs = [
    {
      name: 'Gemini Backend',
      config: {
        "env": {
          "ANTHROPIC_BASE_URL": `${API_BASE}/${AUTH_TOKEN}/claude/gemini`,
          "ANTHROPIC_CUSTOM_HEADERS": "x-api-key: YOUR_GEMINI_API_KEY",
          "ANTHROPIC_MODEL": "gemini-2.5-pro",
          "ANTHROPIC_SMALL_FAST_MODEL": "gemini-2.5-flash"
        }
      }
    },
    {
      name: 'OpenAI Backend', 
      config: {
        "env": {
          "ANTHROPIC_BASE_URL": `${API_BASE}/${AUTH_TOKEN}/claude/openai`,
          "ANTHROPIC_CUSTOM_HEADERS": "x-api-key: YOUR_OPENAI_API_KEY",
          "ANTHROPIC_MODEL": "gpt-4o",
          "ANTHROPIC_SMALL_FAST_MODEL": "gpt-4o-mini"
        }
      }
    }
  ];
  
  configs.forEach(({ name, config }) => {
    console.log(`\n## ${name}`);
    console.log('Edit ~/.claude/settings.json:');
    console.log(JSON.stringify(config, null, 2));
  });
}

// OpenAI SDKé›†æˆæµ‹è¯•
function generateOpenAISDKExample() {
  console.log('\nğŸ”§ OpenAI SDK Integration Examples:');
  console.log('='.repeat(50));
  
  console.log(`
// Using Gemini as OpenAI-compatible backend
const openai = new OpenAI({
  apiKey: 'your-gemini-api-key',
  baseURL: '${API_BASE}/${AUTH_TOKEN}/openai/gemini'
});

const response = await openai.chat.completions.create({
  model: "gemini-2.5-flash",
  messages: [
    {"role": "user", "content": "Hello"}
  ]
});

console.log(response.choices[0].message.content);
`);
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶
if (typeof window === 'undefined' && typeof global !== 'undefined') {
  // Node.jsç¯å¢ƒ
  runAllTests().then(() => {
    generateClaudeCodeConfig();
    generateOpenAISDKExample();
  });
} else {
  // æµè§ˆå™¨ç¯å¢ƒ
  console.log('Run runAllTests() to start testing');
}